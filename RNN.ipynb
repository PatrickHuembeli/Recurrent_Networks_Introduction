{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleRNN(nn.Module):\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        super(SingleRNN, self).__init__()\n",
    "        \n",
    "        self.Wx = torch.randn(n_inputs, n_neurons) # 4 X 1 Defines input weights\n",
    "        self.Wy = torch.randn(n_neurons, n_neurons) # 1 X 1 defines weights between time series\n",
    "        \n",
    "        self.b = torch.zeros(1, n_neurons) # 1 X 4 Defines biases of inputs\n",
    "    \n",
    "    def forward(self, X0, X1):\n",
    "        self.Y0 = torch.tanh(torch.mm(X0, self.Wx) + self.b) # 4 X 1\n",
    "        \n",
    "        self.Y1 = torch.tanh(torch.mm(self.Y0, self.Wy) +\n",
    "                            torch.mm(X1, self.Wx) + self.b) # 4 X 1\n",
    "        \n",
    "        return self.Y0, self.Y1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"RNN_img.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model with one neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_INPUT = 4 # Input dim\n",
    "N_NEURONS = 1\n",
    "\n",
    "X0_batch = torch.tensor([[0,1,2,0], [3,4,5,0], \n",
    "                         [6,7,8,0], [9,0,1,0]],\n",
    "                        dtype = torch.float) #t=0 => 4 X 4\n",
    "\n",
    "X1_batch = torch.tensor([[9,8,7,0], [0,0,0,0], \n",
    "                         [6,5,4,0], [3,2,1,0]],\n",
    "                        dtype = torch.float) #t=1 => 4 X 4\n",
    "\n",
    "model = SingleRNN(N_INPUT, N_NEURONS)\n",
    "\n",
    "Y0_val, Y1_val = model(X0_batch, X1_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9745],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-0.8636]]) tensor([[-1.0000],\n",
      "        [ 0.0091],\n",
      "        [-1.0000],\n",
      "        [-0.9296]])\n"
     ]
    }
   ],
   "source": [
    "print(Y0_val, Y1_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with many neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"RNN_img2.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_INPUT = 3 # number of features in input\n",
    "N_NEURONS = 5 # number of units in layer\n",
    "\n",
    "X0_batch = torch.tensor([[0,1,2], [3,4,5], \n",
    "                         [6,7,8], [9,0,1]],\n",
    "                        dtype = torch.float) #t=0 => 4 X 3\n",
    "\n",
    "X1_batch = torch.tensor([[9,8,7], [0,0,0], \n",
    "                         [6,5,4], [3,2,1]],\n",
    "                        dtype = torch.float) #t=1 => 4 X 3\n",
    "\n",
    "model = SingleRNN(N_INPUT, N_NEURONS)\n",
    "\n",
    "Y0_val, Y1_val = model(X0_batch, X1_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write general RNN with N time_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[-0.9143, -0.7025,  0.1766, -0.9880, -0.6396],\n",
      "        [-0.8793,  0.3464, -0.9270, -0.9081,  0.5711],\n",
      "        [-0.9753,  0.8463, -1.0000, -0.9954,  0.6678],\n",
      "        [ 0.9631,  0.5100, -0.9504,  0.9551,  0.8417]], grad_fn=<TanhBackward>), tensor([[-0.9099,  0.6987, -1.0000, -0.9713,  0.9791],\n",
      "        [ 0.2344, -0.1805,  0.2667, -0.5335, -0.4938],\n",
      "        [-0.7418,  0.7093, -0.9996, -0.9425,  0.6448],\n",
      "        [-0.6043, -0.6888, -0.5357, -0.6534,  0.0255]], grad_fn=<TanhBackward>)]\n",
      "tensor([[-0.9099,  0.6987, -1.0000, -0.9713,  0.9791],\n",
      "        [ 0.2344, -0.1805,  0.2667, -0.5335, -0.4938],\n",
      "        [-0.7418,  0.7093, -0.9996, -0.9425,  0.6448],\n",
      "        [-0.6043, -0.6888, -0.5357, -0.6534,  0.0255]], grad_fn=<TanhBackward>)\n"
     ]
    }
   ],
   "source": [
    "class CleanBasicRNN(nn.Module):\n",
    "    def __init__(self, batch_size, n_inputs, n_neurons, n_time_steps):\n",
    "        super(CleanBasicRNN, self).__init__()\n",
    "        \n",
    "        self.rnn = nn.RNNCell(n_inputs, n_neurons)\n",
    "        self.hx = torch.randn(batch_size, n_neurons) # initialize hidden state\n",
    "        self.n_time_steps = n_time_steps\n",
    "    def forward(self, X):\n",
    "        output = []\n",
    "\n",
    "        # for each time step\n",
    "        for i in range(self.n_time_steps):\n",
    "            self.hx = self.rnn(X[i], self.hx)\n",
    "            output.append(self.hx)\n",
    "        \n",
    "        return output, self.hx\n",
    "\n",
    "FIXED_BATCH_SIZE = 4 # our batch size is fixed for now\n",
    "N_INPUT = 3\n",
    "N_NEURONS = 5\n",
    "\n",
    "X_batch = torch.tensor([[[0,1,2], [3,4,5], \n",
    "                         [6,7,8], [9,0,1]],\n",
    "                        [[9,8,7], [0,0,0], \n",
    "                         [6,5,4], [3,2,1]]\n",
    "                       ], dtype = torch.float) # X0 and X1\n",
    "\n",
    "\n",
    "model = CleanBasicRNN(FIXED_BATCH_SIZE, N_INPUT, N_NEURONS, 2)\n",
    "output_val, states_val = model(X_batch)\n",
    "print(output_val) # contains all output for all timesteps\n",
    "print(states_val) # contains values for final state or final timestep, i.e., t=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# list all transformations\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "\n",
    "# download and load training dataset\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "# download and load testing dataset\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters \n",
    "N_STEPS = 28\n",
    "N_INPUTS = 28\n",
    "N_NEURONS = 150\n",
    "N_OUTPUTS = 10\n",
    "N_EPHOCS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we use RNN instead of RNNCell. This allows us to add also hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageRNN(nn.Module):\n",
    "    def __init__(self, batch_size, n_steps, n_inputs, n_neurons, n_outputs):\n",
    "        super(ImageRNN, self).__init__()\n",
    "        \n",
    "        self.n_neurons = n_neurons\n",
    "        self.batch_size = batch_size\n",
    "        self.n_steps = n_steps\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "        \n",
    "        self.basic_rnn = nn.RNN(self.n_inputs, self.n_neurons) \n",
    "        \n",
    "        self.FC = nn.Linear(self.n_neurons, self.n_outputs)\n",
    "        \n",
    "    def init_hidden(self,):\n",
    "        # (num_layers, batch_size, n_neurons)\n",
    "        return (torch.zeros(1, self.batch_size, self.n_neurons))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # transforms X to dimensions: n_steps X batch_size X n_inputs\n",
    "        X = X.permute(1, 0, 2) \n",
    "        \n",
    "        self.batch_size = X.size(1)\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "        lstm_out, self.hidden = self.basic_rnn(X, self.hidden)      \n",
    "        out = self.FC(self.hidden)\n",
    "        \n",
    "        return out.view(-1, self.n_outputs) # batch_size X n_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
